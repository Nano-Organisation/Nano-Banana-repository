
import { GoogleGenAI, GenerateContentResponse, Chat, Modality } from "@google/genai";
import { EmojiPuzzle, WordPuzzle, TwoTruthsPuzzle, RiddlePuzzle, StorybookData, MemeData } from "../types";

// Note: For Veo calls, we create a fresh instance inside the function to ensure the latest API Key is used.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Helpers
const fileToGenerativePart = (base64Data: string, mimeType: string) => {
  return {
    inlineData: {
      data: base64Data.split(',')[1], // Remove the data url prefix
      mimeType
    },
  };
};

/**
 * Helper to convert Base64 string to Uint8Array
 */
const base64ToUint8Array = (base64: string): Uint8Array => {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
};

/**
 * Helper to write string to DataView
 */
const writeString = (view: DataView, offset: number, string: string) => {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
};

/**
 * Wraps raw PCM data in a WAV container.
 * Assumes 24kHz, 16-bit mono (standard for Gemini Flash TTS).
 */
const pcmToWav = (pcmData: Uint8Array): Blob => {
  const WAV_HEADER_SIZE = 44;
  const buffer = new ArrayBuffer(WAV_HEADER_SIZE + pcmData.length);
  const view = new DataView(buffer);

  // RIFF chunk descriptor
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + pcmData.length, true);
  writeString(view, 8, 'WAVE');

  // fmt sub-chunk
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
  view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
  view.setUint16(22, 1, true); // NumChannels (1 channel)
  view.setUint32(24, 24000, true); // SampleRate (24000Hz)
  view.setUint32(28, 24000 * 2, true); // ByteRate (SampleRate * BlockAlign)
  view.setUint16(32, 2, true); // BlockAlign (NumChannels (1 channel)
  view.setUint16(34, 16, true); // BitsPerSample (16 bits)

  // data sub-chunk
  writeString(view, 36, 'data');
  view.setUint32(40, pcmData.length, true);

  // Write audio data
  const bytes = new Uint8Array(buffer);
  bytes.set(pcmData, 44);

  return new Blob([buffer], { type: 'audio/wav' });
};

/**
 * Chat Session: Uses gemini-2.5-flash
 * Allows custom system instructions for different personas (Assistant, Game Master, etc.)
 */
export const createChatSession = (systemInstruction?: string): Chat => {
  return ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: systemInstruction || "You are a helpful, witty, and concise AI assistant named Nano. You are part of the Nano Banana AI Suite.",
    }
  });
};

/**
 * Thinking Chat Session: Uses gemini-3-pro-preview
 * Uses high thinking budget for complex tasks.
 */
export const createThinkingChatSession = (systemInstruction?: string): Chat => {
  return ai.chats.create({
    model: 'gemini-3-pro-preview',
    config: {
      systemInstruction: systemInstruction || "You are a deep-thinking AI assistant. Use your reasoning capabilities to solve complex problems.",
      thinkingConfig: { thinkingBudget: 32768 } // Max budget for pro
    }
  });
};

/**
 * Image Editing: Uses gemini-2.5-flash-image
 * Input: Image + Text Prompt
 * Output: Edited Image
 */
export const editImageWithGemini = async (base64Image: string, prompt: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-image';
    
    const imagePart = fileToGenerativePart(base64Image, 'image/png'); // Assuming PNG for simplicity in editor
    const textPart = { text: prompt };

    const response = await ai.models.generateContent({
      model,
      contents: {
        parts: [imagePart, textPart]
      }
    });

    // Iterate to find image output
    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    
    throw new Error("No image generated by the model.");
  } catch (error) {
    console.error("Gemini Image Edit Error:", error);
    throw error;
  }
};

/**
 * Image Generation (Standard): Uses gemini-2.5-flash-image
 * Input: Text Prompt
 * Output: New Image
 */
export const generateImageWithGemini = async (prompt: string, aspectRatio: string = '1:1'): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-image';
    
    const response = await ai.models.generateContent({
      model,
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          aspectRatio: aspectRatio
        }
      }
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    throw new Error("No image generated.");
  } catch (error) {
    console.error("Gemini Image Gen Error:", error);
    throw error;
  }
};

/**
 * Image Generation (Pro): Uses gemini-3-pro-image-preview
 * Supports image sizing. Requires Paid API Key.
 */
export const generateProImageWithGemini = async (prompt: string, size: string = '1K'): Promise<string> => {
  try {
    // Pro image generation uses a specific user-selected key if available
    const proAi = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const model = 'gemini-3-pro-image-preview';
    
    const response = await proAi.models.generateContent({
      model,
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          imageSize: size
        }
      }
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    throw new Error("No image generated.");
  } catch (error) {
    console.error("Gemini Pro Image Gen Error:", error);
    throw error;
  }
};

/**
 * Generate 5 Viral YouTube Thumbnails
 * Runs parallel requests with slightly varied prompts to ensure diversity.
 */
export const generateViralThumbnails = async (basePrompt: string): Promise<string[]> => {
  // Variations to ensure different compositions/styles for the same concept
  const variations = [
    "hyper-realistic, close-up face, high contrast, 4k",
    "wide angle action shot, vibrant colors, epic composition",
    "split screen comparison style, text overlay placeholders, bright background",
    "minimalist but shocking, curiosity inducing, high saturation",
    "detailed 3D render style, glossy finish, trending on youtube"
  ];

  const promises = variations.map(variation => 
    generateImageWithGemini(`YouTube thumbnail of ${basePrompt}. ${variation}`, '16:9')
      .catch(e => null) // Catch individual errors so partial results can return
  );

  const results = await Promise.all(promises);
  const successfulImages = results.filter((img): img is string => img !== null);
  
  if (successfulImages.length === 0) {
    throw new Error("Failed to generate thumbnails.");
  }

  return successfulImages;
};

/**
 * Text Generation (Summary, Story, Code): Uses gemini-2.5-flash
 */
export const generateTextWithGemini = async (prompt: string, systemInstruction?: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash';
    
    const response: GenerateContentResponse = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        systemInstruction,
      }
    });

    return response.text || "No response generated.";
  } catch (error) {
    console.error("Gemini Text Gen Error:", error);
    throw error;
  }
};

/**
 * Visual QA: Uses gemini-2.5-flash (Multimodal)
 * Input: Image + Text Question
 * Output: Text Answer
 */
export const analyzeImageWithGemini = async (base64Image: string, prompt: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash';
    const imagePart = fileToGenerativePart(base64Image, 'image/jpeg'); // Assuming JPEG or PNG
    const textPart = { text: prompt };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model,
      contents: { parts: [imagePart, textPart] }
    });

    return response.text || "No analysis generated.";
  } catch (error) {
    console.error("Gemini Visual QA Error:", error);
    throw error;
  }
};

/**
 * Video Generation: Uses veo-3.1-fast-generate-preview
 * Input: Prompt + Optional Image
 * Note: Requires paid API Key
 */
export const generateVideoWithGemini = async (prompt: string, aspectRatio: string = '16:9', imageBase64?: string): Promise<string> => {
  try {
    // Create a NEW instance to pick up any dynamically set API keys
    const veoAi = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    // Prepare request
    const request: any = {
      model: 'veo-3.1-fast-generate-preview',
      prompt: prompt,
      config: {
        numberOfVideos: 1,
        resolution: '720p',
        aspectRatio: aspectRatio 
      }
    };

    if (imageBase64) {
      request.image = {
        imageBytes: imageBase64.split(',')[1],
        mimeType: 'image/png' // Assuming PNG
      };
    }

    let operation = await veoAi.models.generateVideos(request);

    // Poll until complete
    while (!operation.done) {
      await new Promise(resolve => setTimeout(resolve, 5000)); // Poll every 5s
      operation = await veoAi.operations.getVideosOperation({operation: operation});
    }

    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) throw new Error("No video URI returned.");

    // Fetch the actual bytes using the key
    const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
    const blob = await response.blob();
    return URL.createObjectURL(blob);
  } catch (error) {
    console.error("Gemini Video Gen Error:", error);
    throw error;
  }
};

/**
 * Text-to-Speech: Uses gemini-2.5-flash-preview-tts
 */
export const generateSpeechWithGemini = async (
  text: string, 
  voiceName: string = 'Kore',
  speed: number = 1.0,
  pitch: number = 0
): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-preview-tts';
    
    // Construct instructions based on speed and pitch
    const instructions = [];
    if (speed <= 0.7) instructions.push("very slow");
    else if (speed < 1.0) instructions.push("slow");
    else if (speed >= 1.5) instructions.push("very fast");
    else if (speed > 1.0) instructions.push("fast");

    if (pitch <= -2) instructions.push("deep");
    else if (pitch < 0) instructions.push("low");
    else if (pitch >= 2) instructions.push("very high");
    else if (pitch > 0) instructions.push("high");

    let finalPrompt = text;
    if (instructions.length > 0) {
      // Prompt engineering to influence the speech style
      finalPrompt = `Say the following with a ${instructions.join(' and ')} voice: "${text}"`;
    }

    const response = await ai.models.generateContent({
      model,
      contents: { parts: [{ text: finalPrompt }] },
      config: {
        responseModalities: [Modality.AUDIO], 
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: { voiceName }
          }
        }
      }
    });

    // Extract base64 audio data
    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!base64Audio) {
      throw new Error("No audio data generated.");
    }

    // Convert to PCM Uint8Array
    const pcmData = base64ToUint8Array(base64Audio);

    // Wrap in WAV container
    const wavBlob = pcmToWav(pcmData);

    return URL.createObjectURL(wavBlob);
  } catch (error) {
    console.error("Gemini Speech Gen Error:", error);
    throw error;
  }
};

/**
 * Live API Connection Helper
 */
export const getLiveClient = () => {
    return ai.live;
};

/**
 * Emoji Puzzle Generation
 */
export const generateEmojiPuzzle = async (): Promise<EmojiPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a challenging but guessable emoji puzzle.
    Think of a popular movie, book, song, idiom, or famous place.
    Convert it into a sequence of emojis that represent it.
    Return ONLY a JSON object with this format:
    {
      "emojis": "the emoji sequence",
      "answer": "the text title or phrase",
      "category": "Movie/Book/Song/Idiom/Place"
    }
    Do not include markdown formatting like \`\`\`json.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Puzzle Gen Error", error);
    // Fallback puzzle
    return { emojis: "ðŸ‘½ðŸš²ðŸŒ•", answer: "E.T. the Extra-Terrestrial", category: "Movie" };
  }
};

/**
 * Word Puzzle Generation
 */
export const generateWordPuzzle = async (): Promise<WordPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a word spelling puzzle.
    1. Pick a commonly misspelled English word (e.g., intermediate to advanced difficulty).
    2. Provide its dictionary definition (keep it concise, max 20 words).
    3. Provide 2 plausible but incorrect spellings (distractors).
    
    Return ONLY a JSON object with this format:
    {
      "word": "correct_spelling",
      "definition": "the definition of the word",
      "distractors": ["incorrect_spelling_1", "incorrect_spelling_2"]
    }
    Do not include markdown formatting like \`\`\`json.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Word Puzzle Gen Error", error);
    // Fallback puzzle
    return { 
      word: "accommodate", 
      definition: "To provide lodging or sufficient space for.", 
      distractors: ["acommodate", "accomodate"] 
    };
  }
};

/**
 * Two Truths and a Lie Generation
 */
export const generateTwoTruthsPuzzle = async (): Promise<TwoTruthsPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a "Two Truths and a Lie" puzzle about a random interesting topic (e.g., Space, Animals, History, Science).
    Return ONLY a JSON object with this format:
    {
      "topic": "The Topic Name",
      "statements": [
        {"text": "Statement 1", "isTruth": true},
        {"text": "Statement 2", "isTruth": false},
        {"text": "Statement 3", "isTruth": true}
      ],
      "explanation": "A brief explanation of why the lie is false."
    }
    Ensure statements are shuffled. Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Two Truths Gen Error", error);
    return {
      topic: "Bananas",
      statements: [
        { text: "Bananas are berries.", isTruth: true },
        { text: "Bananas grow on trees.", isTruth: false },
        { text: "Humans share 50% of their DNA with bananas.", isTruth: true }
      ],
      explanation: "Bananas actually grow on large herbaceous plants, not trees!"
    };
  }
};

/**
 * Riddle Puzzle Generation
 */
export const generateRiddlePuzzle = async (): Promise<RiddlePuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a clever, rhyming riddle.
    Return ONLY a JSON object with this format:
    {
      "question": "The riddle text",
      "answer": "The answer (1-2 words)",
      "hint": "A subtle clue to help solve it",
      "difficulty": "Easy" or "Medium" or "Hard"
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Riddle Gen Error", error);
    return {
      question: "I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?",
      answer: "Echo",
      hint: "I repeat what you say.",
      difficulty: "Easy"
    };
  }
};

/**
 * Storybook Generation: Steps to create a book with consistent pages.
 */
export const generateStoryScript = async (concept: string, style: string, existingCharacter?: string): Promise<StorybookData> => {
  try {
    const model = 'gemini-2.5-flash';
    let prompt = `You are a children's book author and art director.
    Create a short story (4 pages) based on this concept: "${concept}".
    The visual style is: "${style}".`;

    if (existingCharacter) {
      prompt += `
      IMPORTANT: You must use this PRE-DEFINED character description exactly for the main character: "${existingCharacter}". 
      Do not create a new visual description for the main character, just reuse this one in the 'characterDescription' field.`;
    } else {
      prompt += `
      IMPORTANT: To ensure the main character looks exactly the same on every page, you must define a strict 'characterDescription' first.`;
    }
    
    prompt += `
    Return ONLY a JSON object with the following structure:
    {
      "title": "A catchy title",
      "style": "The visual style description",
      "characterDescription": "A highly detailed, immutable visual description of the main character(s). Include specific details like hair color, clothing style and color, height, and accessories. This exact string will be used to generate every image.",
      "pages": [
        {
          "pageNumber": 1,
          "text": "The story text for page 1 (approx 2-3 sentences)",
          "imagePrompt": "The specific action and setting for page 1. Do NOT re-describe the character's appearance here, just refer to them by name or as 'the character'."
        },
        ...
      ]
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Storybook Script Error", error);
    throw error;
  }
};

/**
 * Meme Concept Generation
 */
export const generateMemeConcept = async (topic: string): Promise<MemeData> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a viral, funny meme concept about: "${topic}".
    1. Write a witty Top Text (setup) and Bottom Text (punchline). Keep them short and uppercase.
    2. Write a visual prompt for an image that matches the joke perfectly. It should be a meme-style background image.
    
    Return ONLY a JSON object with this format:
    {
      "topText": "TOP TEXT HERE",
      "bottomText": "BOTTOM TEXT HERE",
      "visualPrompt": "A description of the image..."
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Meme Gen Error", error);
    throw error;
  }
};
