
import { GoogleGenAI, GenerateContentResponse, Chat, Modality } from "@google/genai";
import { EmojiPuzzle, WordPuzzle, TwoTruthsPuzzle, RiddlePuzzle, StorybookData, MemeData, SocialCampaign, SocialSettings, PromptAnalysis, DailyTip, HelpfulList, PodcastScript } from "../types";

// Note: For Veo calls, we create a fresh instance inside the function to ensure the latest API Key is used.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

// Helpers
const fileToGenerativePart = (base64Data: string, mimeType: string) => {
  return {
    inlineData: {
      data: base64Data.split(',')[1], // Remove the data url prefix
      mimeType
    },
  };
};

/**
 * Helper to convert Base64 string to Uint8Array
 */
const base64ToUint8Array = (base64: string): Uint8Array => {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
};

/**
 * Helper to write string to DataView
 */
const writeString = (view: DataView, offset: number, string: string) => {
  for (let i = 0; i < string.length; i++) {
    view.setUint8(offset + i, string.charCodeAt(i));
  }
};

/**
 * Wraps raw PCM data in a WAV container.
 * Assumes 24kHz, 16-bit mono (standard for Gemini Flash TTS).
 */
const pcmToWav = (pcmData: Uint8Array): Blob => {
  const WAV_HEADER_SIZE = 44;
  const buffer = new ArrayBuffer(WAV_HEADER_SIZE + pcmData.length);
  const view = new DataView(buffer);

  // RIFF chunk descriptor
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + pcmData.length, true);
  writeString(view, 8, 'WAVE');

  // fmt sub-chunk
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // Subchunk1Size (16 for PCM)
  view.setUint16(20, 1, true); // AudioFormat (1 for PCM)
  view.setUint16(22, 1, true); // NumChannels (1 channel)
  view.setUint32(24, 24000, true); // SampleRate (24000Hz)
  view.setUint32(28, 24000 * 2, true); // ByteRate (SampleRate * BlockAlign)
  view.setUint16(32, 2, true); // BlockAlign (NumChannels (1 channel)
  view.setUint16(34, 16, true); // BitsPerSample (16 bits)

  // data sub-chunk
  writeString(view, 36, 'data');
  view.setUint32(40, pcmData.length, true);

  // Write audio data
  const bytes = new Uint8Array(buffer);
  bytes.set(pcmData, 44);

  return new Blob([buffer], { type: 'audio/wav' });
};

/**
 * Chat Session: Uses gemini-2.5-flash
 * Allows custom system instructions for different personas (Assistant, Game Master, etc.)
 */
export const createChatSession = (systemInstruction?: string): Chat => {
  return ai.chats.create({
    model: 'gemini-2.5-flash',
    config: {
      systemInstruction: systemInstruction || "You are a helpful, witty, and concise AI assistant named Nano. You are part of the Nano Banana AI Suite.",
    }
  });
};

/**
 * Thinking Chat Session: Uses gemini-3-pro-preview
 * Uses high thinking budget for complex tasks.
 */
export const createThinkingChatSession = (systemInstruction?: string): Chat => {
  return ai.chats.create({
    model: 'gemini-3-pro-preview',
    config: {
      systemInstruction: systemInstruction || "You are a deep-thinking AI assistant. Use your reasoning capabilities to solve complex problems.",
      thinkingConfig: { thinkingBudget: 32768 } // Max budget for pro
    }
  });
};

/**
 * Image Editing: Uses gemini-2.5-flash-image
 * Input: Image + Text Prompt
 * Output: Edited Image
 */
export const editImageWithGemini = async (base64Image: string, prompt: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-image';
    
    const imagePart = fileToGenerativePart(base64Image, 'image/png'); // Assuming PNG for simplicity in editor
    const textPart = { text: prompt };

    const response = await ai.models.generateContent({
      model,
      contents: {
        parts: [imagePart, textPart]
      }
    });

    // Iterate to find image output
    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    
    throw new Error("No image generated by the model.");
  } catch (error) {
    console.error("Gemini Image Edit Error:", error);
    throw error;
  }
};

/**
 * Image Generation (Standard): Uses gemini-2.5-flash-image
 * Input: Text Prompt
 * Output: New Image
 */
export const generateImageWithGemini = async (prompt: string, aspectRatio: string = '1:1'): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-image';
    
    const response = await ai.models.generateContent({
      model,
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          aspectRatio: aspectRatio
        }
      }
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    throw new Error("No image generated.");
  } catch (error) {
    console.error("Gemini Image Gen Error:", error);
    throw error;
  }
};

/**
 * Image Generation (Pro): Uses gemini-3-pro-image-preview
 * Supports image sizing. Requires Paid API Key.
 */
export const generateProImageWithGemini = async (prompt: string, size: string = '1K'): Promise<string> => {
  try {
    // Pro image generation uses a specific user-selected key if available
    const proAi = new GoogleGenAI({ apiKey: process.env.API_KEY });
    const model = 'gemini-3-pro-image-preview';
    
    const response = await proAi.models.generateContent({
      model,
      contents: { parts: [{ text: prompt }] },
      config: {
        imageConfig: {
          imageSize: size
        }
      }
    });

    if (response.candidates?.[0]?.content?.parts) {
      for (const part of response.candidates[0].content.parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:image/png;base64,${part.inlineData.data}`;
        }
      }
    }
    throw new Error("No image generated.");
  } catch (error) {
    console.error("Gemini Pro Image Gen Error:", error);
    throw error;
  }
};

/**
 * Generate 5 Viral YouTube Thumbnails
 * Runs parallel requests with slightly varied prompts to ensure diversity.
 */
export const generateViralThumbnails = async (basePrompt: string): Promise<string[]> => {
  // Variations to ensure different compositions/styles for the same concept
  const variations = [
    "hyper-realistic, close-up face, high contrast, 4k",
    "wide angle action shot, vibrant colors, epic composition",
    "split screen comparison style, text overlay placeholders, bright background",
    "minimalist but shocking, curiosity inducing, high saturation",
    "detailed 3D render style, glossy finish, trending on youtube"
  ];

  const promises = variations.map(variation => 
    generateImageWithGemini(`YouTube thumbnail of ${basePrompt}. ${variation}`, '16:9')
      .catch(e => null) // Catch individual errors so partial results can return
  );

  const results = await Promise.all(promises);
  const successfulImages = results.filter((img): img is string => img !== null);
  
  if (successfulImages.length === 0) {
    throw new Error("Failed to generate thumbnails.");
  }

  return successfulImages;
};

/**
 * Text Generation (Summary, Story, Code): Uses gemini-2.5-flash
 */
export const generateTextWithGemini = async (prompt: string, systemInstruction?: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash';
    
    const response: GenerateContentResponse = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        systemInstruction,
      }
    });

    return response.text || "No response generated.";
  } catch (error) {
    console.error("Gemini Text Gen Error:", error);
    throw error;
  }
};

/**
 * Visual QA: Uses gemini-2.5-flash (Multimodal)
 * Input: Image + Text Question
 * Output: Text Answer
 */
export const analyzeImageWithGemini = async (base64Image: string, prompt: string): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash';
    const imagePart = fileToGenerativePart(base64Image, 'image/jpeg'); // Assuming JPEG or PNG
    const textPart = { text: prompt };

    const response: GenerateContentResponse = await ai.models.generateContent({
      model,
      contents: { parts: [imagePart, textPart] }
    });

    return response.text || "No analysis generated.";
  } catch (error) {
    console.error("Gemini Visual QA Error:", error);
    throw error;
  }
};

/**
 * Video Generation: Uses veo-3.1-fast-generate-preview
 * Input: Prompt + Optional Image
 * Note: Requires paid API Key
 */
export const generateVideoWithGemini = async (prompt: string, aspectRatio: string = '16:9', imageBase64?: string): Promise<string> => {
  try {
    // Create a NEW instance to pick up any dynamically set API keys
    const veoAi = new GoogleGenAI({ apiKey: process.env.API_KEY });
    
    // Prepare request
    const request: any = {
      model: 'veo-3.1-fast-generate-preview',
      prompt: prompt,
      config: {
        numberOfVideos: 1,
        resolution: '720p',
        aspectRatio: aspectRatio 
      }
    };

    if (imageBase64) {
      request.image = {
        imageBytes: imageBase64.split(',')[1],
        mimeType: 'image/png' // Assuming PNG
      };
    }

    let operation = await veoAi.models.generateVideos(request);

    // Poll until complete
    while (!operation.done) {
      await new Promise(resolve => setTimeout(resolve, 5000)); // Poll every 5s
      operation = await veoAi.operations.getVideosOperation({operation: operation});
    }

    const downloadLink = operation.response?.generatedVideos?.[0]?.video?.uri;
    if (!downloadLink) throw new Error("No video URI returned.");

    // Fetch the actual bytes using the key
    const response = await fetch(`${downloadLink}&key=${process.env.API_KEY}`);
    const blob = await response.blob();
    return URL.createObjectURL(blob);
  } catch (error) {
    console.error("Gemini Video Gen Error:", error);
    throw error;
  }
};

/**
 * Text-to-Speech: Uses gemini-2.5-flash-preview-tts
 * Supports Multi-Speaker when speakerVoiceConfigs are provided.
 */
export const generateSpeechWithGemini = async (
  text: string, 
  voiceName: string = 'Kore',
  speed: number = 1.0,
  pitch: number = 0,
  multiSpeakerConfig?: { speaker: string, voice: string }[]
): Promise<string> => {
  try {
    const model = 'gemini-2.5-flash-preview-tts';
    
    const config: any = {
      responseModalities: [Modality.AUDIO], 
    };

    if (multiSpeakerConfig && multiSpeakerConfig.length === 2) {
      // Multi-Speaker Setup
      config.speechConfig = {
        multiSpeakerVoiceConfig: {
          speakerVoiceConfigs: [
            {
              speaker: multiSpeakerConfig[0].speaker,
              voiceConfig: { prebuiltVoiceConfig: { voiceName: multiSpeakerConfig[0].voice } }
            },
            {
              speaker: multiSpeakerConfig[1].speaker,
              voiceConfig: { prebuiltVoiceConfig: { voiceName: multiSpeakerConfig[1].voice } }
            }
          ]
        }
      };
    } else {
      // Single Speaker Setup with prompt engineering for speed/pitch
      const instructions = [];
      if (speed <= 0.7) instructions.push("very slow");
      else if (speed < 1.0) instructions.push("slow");
      else if (speed >= 1.5) instructions.push("very fast");
      else if (speed > 1.0) instructions.push("fast");

      if (pitch <= -2) instructions.push("deep");
      else if (pitch < 0) instructions.push("low");
      else if (pitch >= 2) instructions.push("very high");
      else if (pitch > 0) instructions.push("high");

      let finalPrompt = text;
      if (instructions.length > 0) {
        finalPrompt = `Say the following with a ${instructions.join(' and ')} voice: "${text}"`;
      }
      
      config.speechConfig = {
        voiceConfig: {
          prebuiltVoiceConfig: { voiceName }
        }
      };
    }

    const response = await ai.models.generateContent({
      model,
      contents: { parts: [{ text: text }] }, // We send the raw text (or prompt engineered text)
      config
    });

    // Extract base64 audio data
    const base64Audio = response.candidates?.[0]?.content?.parts?.[0]?.inlineData?.data;
    
    if (!base64Audio) {
      throw new Error("No audio data generated.");
    }

    // Convert to PCM Uint8Array
    const pcmData = base64ToUint8Array(base64Audio);

    // Wrap in WAV container
    const wavBlob = pcmToWav(pcmData);

    return URL.createObjectURL(wavBlob);
  } catch (error) {
    console.error("Gemini Speech Gen Error:", error);
    throw error;
  }
};

/**
 * Generate Podcast Script
 */
export const generatePodcastScript = async (topic: string, hostName: string, guestName: string): Promise<PodcastScript> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Write a short, engaging podcast script (approx 1 minute) about: "${topic}".
    Characters: ${hostName} (Host) and ${guestName} (Guest).
    
    Format the script EXACTLY like this for the TTS engine:
    ${hostName}: [Text]
    ${guestName}: [Text]
    
    Keep it conversational, witty, and natural.
    Also generate a visual prompt for the podcast cover art.
    
    Return ONLY a JSON object:
    {
      "title": "Podcast Title",
      "script": "The full script string...",
      "visualPrompt": "Cover art description..."
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Podcast Script Error", error);
    throw error;
  }
};

/**
 * Live API Connection Helper
 */
export const getLiveClient = () => {
    return ai.live;
};

/**
 * Emoji Puzzle Generation
 */
export const generateEmojiPuzzle = async (): Promise<EmojiPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a challenging but guessable emoji puzzle.
    Think of a popular movie, book, song, idiom, or famous place.
    Convert it into a sequence of emojis that represent it.
    Return ONLY a JSON object with this format:
    {
      "emojis": "the emoji sequence",
      "answer": "the text title or phrase",
      "category": "Movie/Book/Song/Idiom/Place"
    }
    Do not include markdown formatting like \`\`\`json.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Puzzle Gen Error", error);
    // Fallback puzzle
    return { emojis: "üëΩüö≤üåï", answer: "E.T. the Extra-Terrestrial", category: "Movie" };
  }
};

/**
 * Word Puzzle Generation
 */
export const generateWordPuzzle = async (): Promise<WordPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a word spelling puzzle.
    1. Pick a commonly misspelled English word (e.g., intermediate to advanced difficulty).
    2. Provide its dictionary definition (keep it concise, max 20 words).
    3. Provide 2 plausible but incorrect spellings (distractors).
    
    Return ONLY a JSON object with this format:
    {
      "word": "correct_spelling",
      "definition": "the definition of the word",
      "distractors": ["incorrect_spelling_1", "incorrect_spelling_2"]
    }
    Do not include markdown formatting like \`\`\`json.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Word Puzzle Gen Error", error);
    // Fallback puzzle
    return { 
      word: "accommodate", 
      definition: "To provide lodging or sufficient space for.", 
      distractors: ["acommodate", "accomodate"] 
    };
  }
};

/**
 * Two Truths and a Lie Generation
 */
export const generateTwoTruthsPuzzle = async (): Promise<TwoTruthsPuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a "Two Truths and a Lie" puzzle about a random interesting topic (e.g., Space, Animals, History, Science).
    Return ONLY a JSON object with this format:
    {
      "topic": "The Topic Name",
      "statements": [
        {"text": "Statement 1", "isTruth": true},
        {"text": "Statement 2", "isTruth": false},
        {"text": "Statement 3", "isTruth": true}
      ],
      "explanation": "A brief explanation of why the lie is false."
    }
    Ensure statements are shuffled. Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Two Truths Gen Error", error);
    return {
      topic: "Bananas",
      statements: [
        { text: "Bananas are berries.", isTruth: true },
        { text: "Bananas grow on trees.", isTruth: false },
        { text: "Humans share 50% of their DNA with bananas.", isTruth: true }
      ],
      explanation: "Bananas actually grow on large herbaceous plants, not trees!"
    };
  }
};

/**
 * Riddle Puzzle Generation
 */
export const generateRiddlePuzzle = async (): Promise<RiddlePuzzle> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a clever, rhyming riddle.
    Return ONLY a JSON object with this format:
    {
      "question": "The riddle text",
      "answer": "The answer (1-2 words)",
      "hint": "A subtle clue to help solve it",
      "difficulty": "Easy" or "Medium" or "Hard"
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Riddle Gen Error", error);
    return {
      question: "I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?",
      answer: "Echo",
      hint: "I repeat what you say.",
      difficulty: "Easy"
    };
  }
};

/**
 * Storybook Generation: Steps to create a book with consistent pages.
 */
export const generateStoryScript = async (concept: string, style: string, existingCharacter?: string): Promise<StorybookData> => {
  try {
    const model = 'gemini-2.5-flash';
    let prompt = `You are a children's book author and art director.
    Create a short story (4 pages) based on this concept: "${concept}".
    The visual style is: "${style}".`;

    if (existingCharacter) {
      prompt += `
      IMPORTANT: You must use this PRE-DEFINED character description exactly for the main character: "${existingCharacter}". 
      Do not create a new visual description for the main character, just reuse this one in the 'characterDescription' field.`;
    } else {
      prompt += `
      IMPORTANT: To ensure the main character looks exactly the same on every page, you must define a strict 'characterDescription' first.`;
    }
    
    prompt += `
    Return ONLY a JSON object with the following structure:
    {
      "title": "A catchy title",
      "style": "The visual style description",
      "characterDescription": "A highly detailed, immutable visual description of the main character(s). Include specific details like hair color, clothing style and color, height, and accessories. This exact string will be used to generate every image.",
      "pages": [
        {
          "pageNumber": 1,
          "text": "The story text for page 1 (approx 2-3 sentences)",
          "imagePrompt": "The specific action and setting for page 1. Do NOT re-describe the character's appearance here, just refer to them by name or as 'the character'."
        },
        ...
      ]
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Storybook Script Error", error);
    throw error;
  }
};

/**
 * Meme Concept Generation
 */
export const generateMemeConcept = async (topic: string): Promise<MemeData> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a viral, funny meme concept about: "${topic}".
    1. Write a witty Top Text (setup) and Bottom Text (punchline). Keep them short and uppercase.
    2. Write a visual prompt for an image that matches the joke perfectly. It should be a meme-style background image.
    
    Return ONLY a JSON object with this format:
    {
      "topText": "TOP TEXT HERE",
      "bottomText": "BOTTOM TEXT HERE",
      "visualPrompt": "A description of the image..."
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Meme Gen Error", error);
    throw error;
  }
};

/**
 * Nano Social Campaign Generation
 * Updates: Supports platform selection, tone, style, language, and emoji toggle.
 */
export const generateSocialCampaign = async (topic: string, settings?: SocialSettings): Promise<SocialCampaign> => {
  try {
    const model = 'gemini-2.5-flash';
    
    const platforms = settings?.platforms || ['linkedin', 'twitter', 'instagram'];
    const tone = settings?.tone || 'Professional yet engaging';
    const style = settings?.style || 'Standard';
    const lang = settings?.language || 'English';
    
    let emojiInstruction = "STRICTLY NO EMOJIS. Do not include any emojis in the text.";
    if (settings?.useEmojis) {
       emojiInstruction = `Use relevant emojis tailored to each specific platform's culture:
        - LinkedIn: Use professional, minimal symbols (e.g., üöÄ, üìà, üí°, ‚úÖ). Avoid excessive or casual yellow face emojis.
        - Twitter/X: Use punchy, functional emojis (e.g., üßµ, üëá, üî•, üö®).
        - Instagram: Use visual, aesthetic, and expressive emojis matching the photo vibe (e.g., ‚ú®, üì∏, üåø, üé®).
        - Facebook: Use friendly, community-oriented emojis (e.g., üëã, ‚ù§Ô∏è, üòä, üëç).
        - TikTok: Use high-energy, trending, or slang-appropriate emojis (e.g., üíÄ, üò≠, ‚ö°Ô∏è, üëÄ, üî•).
        - YouTube Shorts: Use attention-grabbing, urgent emojis (e.g., üî¥, üò±, ‚ñ∂Ô∏è, üí•).
        - Threads: Use conversational, casual emojis (e.g., ‚òïÔ∏è, üí≠, üßµ).
        - Pinterest: Use aesthetic, decorative emojis for lists/titles (e.g., üìå, üé®, ‚ú®, üå∏).`;
    }

    const prompt = `You are an expert Social Media Manager. Create a cohesive "Write Once, Post Everywhere" campaign about: "${topic}".
    
    CONFIGURATION:
    - Tone: ${tone}
    - Style: ${style}
    - Language: ${lang}
    - Emoji Rule: ${emojiInstruction}
    
    PLATFORMS TO GENERATE (Generate content ONLY for these): ${platforms.join(', ')}.
    
    INSTRUCTIONS:
    - LinkedIn: Professional, industry insights.
    - Twitter: Thread format (array of strings), punchy hooks.
    - Instagram: Visual focus, engaging caption + hashtags.
    - Facebook: Conversational, community-focused, engaging.
    - TikTok: A short, engaging video script (concept & narration) optimized for high retention.
    - YouTube Shorts: SEO Title + Description + Short Video Script concept.
    - Threads: Conversational, question-based, community engagement focus.
    - Pinterest: Pin Title + Pin Description. Highly visual focus.

    For each selected platform, provide a visual image prompt that matches the content and platform vibe.

    Return ONLY a JSON object with this structure (omit keys for platforms NOT selected):
    {
      "topic": "${topic}",
      "linkedin": { "text": "...", "imagePrompt": "..." },
      "twitter": { "text": ["...", "..."], "imagePrompt": "..." },
      "instagram": { "text": "...", "hashtags": "...", "imagePrompt": "..." },
      "facebook": { "text": "...", "imagePrompt": "..." },
      "tiktok": { "text": "...", "imagePrompt": "..." },
      "youtube_shorts": { "text": "...", "imagePrompt": "..." },
      "threads": { "text": "...", "imagePrompt": "..." },
      "pinterest": { "text": "Title: ... Description: ...", "imagePrompt": "..." }
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Social Campaign Gen Error", error);
    throw error;
  }
};

/**
 * Prompt Engineering Trainer
 * Analyzes prompts based on specific platform best practices.
 */
export const analyzePrompt = async (userPrompt: string, platform: string): Promise<PromptAnalysis> => {
  try {
    const model = 'gemini-2.5-flash';
    
    const prompt = `You are an expert Lead Prompt Engineer specializing in Large Language Models.
    Analyze the following user prompt intended for the platform: "${platform}".

    Target Platform nuances you should know:
    - OpenAI / ChatGPT: Prefers clear personas ("Act as..."), explicit steps, and output format constraints.
    - Google Gemini: Excel at reasoning and multimodal context. Prefers clear instructions without excessive fluff.
    - Anthropic Claude: Excels with XML tags (<context>...</context>) to structure input and clear role prompting.
    - Microsoft Copilot: Prefers concise, goal-oriented instructions, often business-focused.
    - Perplexity: Prefers research-oriented queries, asking for sources or citations.
    - Midjourney: Prefers comma-separated keywords, stylistic parameters (--ar, --v), and less conversational grammar.

    USER PROMPT:
    "${userPrompt}"

    Evaluate the prompt based on clarity, context, constraints, and platform-specific optimization.
    
    If the prompt is already optimal (score > 90), do not suggest major changes.
    
    Return ONLY a JSON object with this structure:
    {
      "score": number (0-100),
      "isOptimal": boolean (true if score > 90),
      "strengths": ["list", "of", "pros"],
      "weaknesses": ["list", "of", "cons"],
      "suggestion": "The improved version of the prompt (optimized for ${platform})",
      "reasoning": "A brief explanation of WHY the suggestion is better (metadata/theory).",
      "platformAdvice": "Specific tip for ${platform} used in this optimization."
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Prompt Analysis Error", error);
    throw error;
  }
};

/**
 * Generate Infinite Daily Tip
 */
export const generateDailyTip = async (dayIndex: number): Promise<DailyTip> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Generate a unique, high-quality "Tip of the Day" for AI Prompt Engineering or AI Security.
    
    This is for Day ${dayIndex} of a learning program.
    Ensure the tip is advanced, practical, and distinct from generic advice.
    
    Structure the response as a valid JSON object:
    {
      "dayIndex": ${dayIndex},
      "date": "${new Date().toISOString()}",
      "category": "Prompting" or "Security" (Pick one randomly),
      "title": "Catchy Title",
      "content": "The main advice (2-3 sentences)",
      "example": "A concrete prompt example or scenario (optional)"
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("Daily Tip Error", error);
    // Fallback
    return {
      dayIndex: dayIndex,
      date: new Date().toISOString(),
      category: 'Prompting',
      title: 'Context Window Awareness',
      content: 'Remember that LLMs have a limited context window. For very long conversations, summarize previous key points to keep the model focused.',
      example: '"Summarize our conversation so far, then answer this..."'
    };
  }
};

/**
 * Generate Helpful List
 */
export const generateHelpfulList = async (topic: string): Promise<HelpfulList> => {
  try {
    const model = 'gemini-2.5-flash';
    const prompt = `Create a helpful, actionable checklist/list for the following topic: "${topic}".
    
    The list could be for Cleaning, Self-Care, Language Learning, Moving House, etc.
    1. Create a catchy Title and a brief Description.
    2. Generate 10-15 actionable items.
    3. Write a visual image prompt for a header image that matches the list theme.
    
    Return ONLY a JSON object:
    {
      "title": "List Title",
      "description": "Brief inspiring description",
      "items": ["Item 1", "Item 2", ...],
      "imagePrompt": "Visual description for header image"
    }
    Do not include markdown formatting.`;

    const response = await ai.models.generateContent({
      model,
      contents: prompt,
      config: {
        responseMimeType: 'application/json'
      }
    });

    const text = response.text;
    if (!text) throw new Error("No text returned");
    return JSON.parse(text);
  } catch (error) {
    console.error("List Gen Error", error);
    throw error;
  }
};